# (PART) Applications of dplyr and tidyr {-}

# Formatted Summary Statistics

You now have the tools for efficiently managing data in one or multiple objects! You may be wondering "What do I do with my new found skills?". In the chapter that follows, I will illustrate how dplyr and tidyr can be harnessed to quickly complete a foundational task for any professional working with data: calculate summary statistics. 

## A Quick Review: Necessary Base Functions
There are a few key base R functions that are necessary for you to know by heart. These are listed below along with their arguments and defaults. If you have questions, remember you can use `?function_name` to open the help file. 


Central Tendency Functions

      - `mean(x, trim = 0, na.rm = FALSE)`
      - `median(x, na.rm = FALSE)`
      
Spread Functions

      - `var(x, na.rm = FALSE)`
      - `sd(x, na.rm = FALSE)`
      
Measures of Association (A preview of things to come)

      - `cor(x, y = NULL, use = "everything", method = "peason")`
      - `cov(x, y = NULL, use = "everything", method = "peason")`
      

## Beyond Base R

There are a few functions that I have found especially helpful over the years. The standard base R functions do not provide hypothesis tests along with measures of association. The correlation function in the psycho package provides this and more! Table formatting also takes a ton of time! The apaTables function stream lines this process 

```{r, eval = FALSE}
install.packages("psycho")
install.packages("apaTables")
install.packages("skimr")
```

Measures of Association
      - `psycho::correlation(df, type = "full", method = "peason", adjust = "holm", i_am_cheating = FALSE)`

Unformatted Summary Statistics
      -`skimr::skim(data)`

Formatted Summary Tables
      - `apaTables::apa.cor.table(data, filename = NA, table.number = NA, showconf.interval = TRUE, landscape = TRUE)`

## Prepping Environment
As always, it is necessary to load packages into the environment. This makes the functions within tha pacakges callable without some additional voodoo. This code chunk, I also load the Chaterjee-Price Attitude Data. This is an employee survey of clerical employees in a financial organization. Type `?attitude`to learn more.

```{r, message = FALSE, warning = FALSE}
# Loading required packages
library(psycho)
library(skimr)
library(kableExtra)
library(apaTables)
library(tidyverse)

# Loading Data from built-in data set
attitude_data<-attitude
```


## Inspecting Data
Prior to diving into the data, lets inspect it to see what we are dealing with. 
```{r}
# Printing an overview of the data
glimpse(attitude_data)

# Verifying that the double type is actually numeric
mode(attitude_data$rating)
```

It looks like we are dealing with 30 observations of 7 variables. Each of these variables is a double (meaning they have a numeric mode). Based on this information, it is safe to say that we can treat this data as numeric and calculate summary statistics reporting the central tendency, spread, and association between these variables. 

## Quick and Dirty Mean and Central Tendency

### skim() for Basic Summary Statistics
When working with data initially, it is useful to calculate a wide variety of summary statistics. This provides the scientist with an idea about how their data looks, what its scale is, and how interrelated variables are. 

`skim()` in the skimr package calculates a range of summary statistics and histograms! It even treats categorical variables differently, if you have them, returning frequencies and levels. All you have to do is pass it a data frame!

```{r}
skim(attitude_data)
```

### summarise() for Custom Summary Statistics
`skim()` is very useful, but doesn't give all the information you may need! Notice that `skim()` doesn't produce the variance of the objects. While that is easy to get to from sd, we can use `summarise()` to get this information directly from the data. 

```{r}
attitude_data%>%
  summarise(
            advance_var = var(advance),
            complaints_var = var(complaints),
            privileges_var = var(privileges),
            learning_var = var(learning), 
            raises_var = var(raises), 
            critical_var = var(critical))
```

That was a lot of typeing the same basic thing, over and over! Remember `summarise_if()`? We can use `summarise_if()` along with the appropriate predicate function to calculate the variance of all numeric variables! Since our goal is to summarise the numeric variables our predicate will be `is.numeric`.

```{r}
attitude_data%>%
  summarise_if(.predicate = is.numeric, .funs = list(var = var))
```

## Quick and Dirty Measures of Association

The above functions are great for summarising the central tendency and spread of variables in a data, but we have gained little insight into how the varaibles are associated. `cov()` and `cor()` return variance-covariance and correlation matrices respectively. These scales provide an indice of association between variables. More positive numbers suggest a stronger positive association and more negative numbers suggest a stronger negative association. Note that differences in scale (i.e., spread) makes different covariances difficult to compare. Correlations are on a standard scale and give more insight into the relative proportion of variance explained.

```{r}
# Covariance
cov(attitude_data)
```

```{r}
# Correlation
cor(attitude_data)
```

### Measures of Association With Hypothesis Tests
While the base R functions are nice, they do not provide any indication about the confidence in our estimate. `correlation()` in the psycho package provides a verbal interpretation along with signicance tests which have been corrected for multiple comparisons. 

```{r}
# Using the correlation function in psycho
my_correlation<-correlation(attitude_data)

# Printing the textual interpretation
my_correlation$text

# Inspecting the correlelogram
my_correlation$plot

# Printing the correlation table with significance values
my_correlation$summary

```

### Formatted APA Summary Statistics

Reporting summary statistics typically requires a bit more work to be put into formatting. However, `apa.cor.table()` really makes the job as easy as possible. The only thing we really have to do is ensure that are variables are properly named and capitalized before calling the function. This is because they will be used directly in the generated table. For the attitude_data, we just need to capitlize the variables. I use rename_all() to do this quickly


```{r}
attitude_data%>%
  rename_all(.funs = ~str_to_sentence(.))%>%
apa.cor.table(filename = "APA_Attitude_Table.doc", table.number = 1)
```


